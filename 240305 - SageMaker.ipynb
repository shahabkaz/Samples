{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b8b5984",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import boto3 # to be able to interact with AWS services such as S3 for data storage (e.g. reading from s3 bucket)\n",
    "\"\"\"\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri # this is used to retrieve the URI (Uniform Resource Identifier) ...\n",
    "                                                            # ... for a specific built-in algorithm container image provided ...\n",
    "                                                            # ... by Amazon\n",
    "\"\"\"\n",
    "from sagemaker import image_uris # new version of get_image_uri\n",
    "from sagemaker.session import s3_input, Session # if we want to use instances of sagemaker, we need to have session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5827b372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu-central-1\n"
     ]
    }
   ],
   "source": [
    "# we can create the buckets form here:\n",
    "bucket_name = 'mlnovo' # Change it to the name of bucket you have created in AWS S3\n",
    "my_region = boto3.session.Session().region_name # based on the region, we can create different buckets, folders, ...\n",
    "print(my_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4890224c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# The next step is to create the bucket name based on the region\\ns3 = boto3.resource('s3')\\ntry:\\n    if my_region == 'us-east-1':\\n        s3.create_bucket(Bucket=bucket_name)\\n    print('S3 bucket created successfully')\\nexcept Exception as e: \\n    print('S3 error:', e)\\n\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# The next step is to create the bucket name based on the region\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if my_region == 'us-east-1':\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e: \n",
    "    print('S3 error:', e)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de8d1a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://mlnovo/xgboost-as-a-built-in_alg/output\n"
     ]
    }
   ],
   "source": [
    "# set the output path where the trained model is saved\n",
    "prefix = 'xgboost-as-a-built-in_alg'\n",
    "output_path = 's3://{}/{}/output'.format(bucket_name, prefix)\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e28eaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: downloaded bank_clean.csv.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "# Downloading the dataset and storing it in S3\n",
    "import pandas as pd\n",
    "import urllib\n",
    "try:\n",
    "    urllib.request.urlretrieve (\"https://d1.awsstatic.com/tmt/build-train-deploy-machine-learning-model-sagemaker/bank_clean.27f01fbbdf43271788427f3682996ae29ceca05d.csv\", \"bank_clean.csv\")\n",
    "    print('Success: downloaded bank_clean.csv.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "    model_data = pd.read_csv('./bank_clean.csv',index_col=0)\n",
    "    print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57adfa02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28831, 61) (12357, 61)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "### Train Test split\n",
    "\n",
    "import numpy as np\n",
    "train_data, test_data = np.split(model_data.sample(frac=1, random_state=1729), [int(0.7 * len(model_data))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b39c2d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving Train And Test Into Buckets\n",
    "## We start with Train Data\n",
    "import os\n",
    "pd.concat([train_data['y_yes'], train_data.drop(['y_no', 'y_yes'], \n",
    "                                                axis=1)], \n",
    "                                                axis=1).to_csv('train.csv', index=False, header=False)\n",
    "# uploading the CSV file into S3 bucket\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "# Reading the training data from S3 bucket and loading it to sagemaker as the \"input train data sample\"\n",
    "s3_input_train = sagemaker.TrainingInput(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')\n",
    "\n",
    "# Loading Test Data Into Buckets\n",
    "pd.concat([test_data['y_yes'], test_data.drop(['y_no', 'y_yes'], axis=1)], axis=1).to_csv('test.csv', index=False, header=False)\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'test/test.csv')).upload_file('test.csv')\n",
    "s3_input_test = sagemaker.TrainingInput(s3_data='s3://{}/{}/test'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "372e223b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu-central-1\n"
     ]
    }
   ],
   "source": [
    "# Building models \"XGBoost in built alg\"\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "# Whenever we use an in-built model from sagemaker, we have to load a container and we do it using get_image_uri\n",
    "\n",
    "print(boto3.Session().region_name)\n",
    "\n",
    "container = image_uris.retrieve('xgboost', boto3.Session().region_name, version=\"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72569004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"5\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"binary:logistic\",\n",
    "        \"num_round\":50\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c10a4541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=sagemaker.get_execution_role(),\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.2xlarge', \n",
    "                                          volume_size=5, # 5 GB \n",
    "                                          output_path=output_path,\n",
    "                                          use_spot_instances=True,\n",
    "                                          max_run=300,\n",
    "                                          max_wait=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "286b7168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: xgboost-2024-03-05-14-00-52-306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-05 14:00:52 Starting - Starting the training job...\n",
      "2024-03-05 14:01:13 Starting - Preparing the instances for training......\n",
      "2024-03-05 14:02:21 Downloading - Downloading input data...\n",
      "2024-03-05 14:02:51 Downloading - Downloading the training image...\n",
      "2024-03-05 14:03:12 Training - Training image download completed. Training in progress...\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2024-03-05:14:03:30:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2024-03-05:14:03:30:INFO] File size need to be processed in the node: 4.83mb. Available memory size in the node: 23948.5mb\u001b[0m\n",
      "\u001b[34m[2024-03-05:14:03:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:03:30] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:03:30] 28831x59 matrix with 1701029 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2024-03-05:14:03:30:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:03:30] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:03:30] 12357x59 matrix with 729063 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.100933#011validation-error:0.105932\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.099442#011validation-error:0.103747\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.099754#011validation-error:0.103423\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.09958#011validation-error:0.103909\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.099338#011validation-error:0.103099\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.099719#011validation-error:0.103099\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.099442#011validation-error:0.102614\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.099476#011validation-error:0.102938\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.099338#011validation-error:0.103099\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.099546#011validation-error:0.103019\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.099199#011validation-error:0.102857\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.098991#011validation-error:0.103099\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.098991#011validation-error:0.10318\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.099025#011validation-error:0.103261\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.098679#011validation-error:0.103261\u001b[0m\n",
      "\u001b[34m[14:03:30] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.098644#011validation-error:0.103342\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.098644#011validation-error:0.103504\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.098679#011validation-error:0.103666\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.09847#011validation-error:0.103423\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.098401#011validation-error:0.104071\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.098297#011validation-error:0.103909\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.098332#011validation-error:0.104475\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.09854#011validation-error:0.104313\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.098332#011validation-error:0.104637\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.098297#011validation-error:0.104718\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.098297#011validation-error:0.104475\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.098228#011validation-error:0.104394\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 38 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.09795#011validation-error:0.104475\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.098158#011validation-error:0.104556\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.098124#011validation-error:0.104637\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.097811#011validation-error:0.104394\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.097742#011validation-error:0.104475\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.097603#011validation-error:0.104718\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.097638#011validation-error:0.104961\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.097603#011validation-error:0.104475\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.097673#011validation-error:0.104556\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.097534#011validation-error:0.104799\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.097569#011validation-error:0.10488\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.097256#011validation-error:0.105284\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.097152#011validation-error:0.105446\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.097048#011validation-error:0.105689\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 28 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.097048#011validation-error:0.105689\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.096806#011validation-error:0.105689\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.09691#011validation-error:0.105932\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.096944#011validation-error:0.106013\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.097014#011validation-error:0.105608\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.096979#011validation-error:0.105932\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.097256#011validation-error:0.10577\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.097256#011validation-error:0.105204\u001b[0m\n",
      "\u001b[34m[14:03:31] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.097048#011validation-error:0.105284\u001b[0m\n",
      "\n",
      "2024-03-05 14:03:48 Uploading - Uploading generated training model\n",
      "2024-03-05 14:03:48 Completed - Training job completed\n",
      "Training seconds: 87\n",
      "Billable seconds: 36\n",
      "Managed Spot Training savings: 58.6%\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'train': s3_input_train,'validation': s3_input_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f785e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: xgboost-2024-03-05-14-09-47-656\n",
      "INFO:sagemaker:Creating endpoint-config with name xgboost-2024-03-05-14-09-47-656\n",
      "INFO:sagemaker:Creating endpoint with name xgboost-2024-03-05-14-09-47-656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "# Deploying ML model as endpoint\n",
    "xgb_predictor = estimator.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe44fbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12357,)\n"
     ]
    }
   ],
   "source": [
    "# Predcition of the test data\n",
    "from sagemaker import serializers\n",
    "test_data_array = test_data.drop(['y_no', 'y_yes'], axis=1).values #load the data into an array\n",
    "xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "xgb_predictor.serializer = serializers.CSVSerializer() # set the serializer type\n",
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d198768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05578489, 0.04585116, 0.05088526, ..., 0.03450042, 0.03321051,\n",
       "       0.03635123])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb33195",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions_array), rownames=['Observed'], colnames=['Predicted'])\n",
    "tn = cm.iloc[0,0]; fn = cm.iloc[1,0]; tp = cm.iloc[1,1]; fp = cm.iloc[0,1]; p = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "print(\"\\n{0:<20}{1:<4.1f}%\\n\".format(\"Overall Classification Rate: \", p))\n",
    "print(\"{0:<15}{1:<15}{2:>8}\".format(\"Predicted\", \"No Purchase\", \"Purchase\"))\n",
    "print(\"Observed\")\n",
    "print(\"{0:<15}{1:<2.0f}% ({2:<}){3:>6.0f}% ({4:<})\".format(\"No Purchase\", tn/(tn+fn)*100,tn, fp/(tp+fp)*100, fp))\n",
    "print(\"{0:<16}{1:<1.0f}% ({2:<}){3:>7.0f}% ({4:<}) \\n\".format(\"Purchase\", fn/(tn+fn)*100,fn, tp/(tp+fp)*100, tp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleting the endpoints\n",
    "sagemaker.Session().delete_endpoint(xgb_predictor.endpoint)\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket_name)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
