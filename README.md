# Samples
Some of my sample codes in R, SAS, and Python.

The most important and related samples:
1. Advanced Marketing Research Exam (including the Excel file): Calculating revenues and retention rate with some input parameters in the attached exam.
    Advanced Marketing Research Exam.pdf: Both questions and my answers (perfect grade)
2. Applied Econometric Methods Exam (The codes have been run in EViews): It exam tests some important and practical statistical methods and concepts.
    Applied Econometric Methods.pdf: Questions
    Econometric Exam: My answers (perfect grade)
3. Bayesian Networks Exam (including the R code): Creating Bayesian Netowrks to analyzing the data we have in the attached exam.
    ECON_460152E040_BayesianNetworks_S16r.pdf: Questions
    Bayesian Networks Exam.pdf: My answers (perfect grade)
4. Data Mining Exam: Finding a good prediction model for the problem in the exam. The folder includes followiong three files.
    ECON_460263E041_DataMiningForBusinessDec_S16o.pdf: Exam questions
    pumpitup.csv: Input dataset
    Data Mining Exam: My answers (10 / 12)
5. Data Science Exam: Visualizing the same problem in Data Mining Exam (including the R code). In addition I have run different ML models on the same data.
6. Data Warehouse Exam: Answering some conceptual issues regarding the implementation of a Data Warehouse.
    ECON_460132E009_DataWarehousing_V2015o.pdf: Questions
    Data Warehouse Exam.pdf: My answers (perfect grade)
7. Machine Learning Exam.pdf: Applying ML algorithms to some problems e.g. detecting the hand written numbers, clustring ... ; but you see just answers.
8. Churn Prediction: A sample of prediction of "churn". Description is in file.
9. LEGO project
    LEGO - Topic Modeling.pdf: Topic modeling on project descriptions. The words with their probabilities on each topic have been come on page 13. For example in 10 topics:
        0, '0.037*"building" + 0.030*"city" + 0.028*"floor" + 0.025*"room" + 0.020*"roof"'), 
        1, '0.052*"house" + 0.026*"robot" + 0.026*"table" + 0.017*"family" + 0.014*"bed"'), 
        2, '0.040*"en" + 0.038*"de" + 0.037*"dir" + 0.018*"la" + 0.017*"le"'), 
        3, '0.033*"red" + 0.025*"black" + 0.024*"blue" + 0.024*"white" + 0.020*"tree"'), 
        4, '0.024*"minifigures"+ 0.020*"includes" + 0.017*"figure" + 0.016*"series" + 0.016*"mini"'), 
        5, '0.059*"lang" + 0.045*"id" + 0.037*"ltr" + 0.036*"p" + 0.022*"spanspan"'), 
        6, '0.041*"car" + 0.015*"vehicle" + 0.014*"feature" + 0.014*"truck" + 0.013*"engine"'), 
        7, '0.085*"game" + 0.020*"hero" + 0.013*"sword" + 0.011*"ninjago" + 0.011*"video"'), 
        8, '0.028*"piece" + 0.022*"brick" + 0.015*"it" + 0.015*"great" + 0.014*"space"'), 
        9, '0.053*"war" + 0.016*"fighter" + 0.013*"mountain" + 0.010*"clone" + 0.009*"imperial"')
    The sample still has a few verbs that the libraries could bot detect to drop them out, so we have to do it in our data cleansing phase (e.g. "includes" and "clone").
